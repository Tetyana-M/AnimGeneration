{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfx_LOy6NEUl"
      },
      "outputs": [],
      "source": [
        "#------------------------------------------------------------------------------#\n",
        "# Imports\n",
        "#------------------------------------------------------------------------------#\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dropout, Dense, LSTM, GRU\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "np.set_printoptions(precision=6)\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "# Supress warnings.\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load dataset.\n",
        "df = pd.read_csv('./data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTK6_jpeiUdo"
      },
      "outputs": [],
      "source": [
        "#------------------------------------------------------------------------------#\n",
        "# Preprocessing\n",
        "#------------------------------------------------------------------------------#\n",
        "\n",
        "# Convert 'time' to datetime format.\n",
        "train_set_dates = pd.to_datetime(df['time'])\n",
        "\n",
        "# Convert the rest to float.\n",
        "columns = list(df.columns[1:55])\n",
        "df_train = df[columns].astype(float)\n",
        "\n",
        "# Normalize the data using the Standard scaler.\n",
        "standard_scaler = StandardScaler()\n",
        "scalar = standard_scaler.fit(df_train)\n",
        "scaled_training_df = scalar.transform(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGVTtdIQDktP",
        "outputId": "8ec5dc01-f941-40d1-fc26-45d46050271b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainX shape: (11200, 900, 54)\n"
          ]
        }
      ],
      "source": [
        "#------------------------------------------------------------------------------#\n",
        "# Create sliding windows for training.\n",
        "#------------------------------------------------------------------------------#\n",
        "future_num = 900 # num of rows to predict the future values\n",
        "past_num = 900 # number of rows on which the prediction is computed\n",
        "\n",
        "trainX = []\n",
        "\n",
        "for i in range(past_num, len(scaled_training_df) - future_num+1):\n",
        "    window = scaled_training_df[i - past_num:i, 0:df_train.shape[1]]\n",
        "    trainX.append(window)\n",
        "\n",
        "trainX = np.array(trainX)\n",
        "\n",
        "print(f'trainX shape: {trainX.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "Unkxf2USx-Rq",
        "outputId": "52dee707-5533-451e-c8a1-4d872cd1f667"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">900</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">23,040</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,408</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">900</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">29,700</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m900\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m23,040\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m9,408\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m900\u001b[0m)                 │          \u001b[38;5;34m29,700\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62,148</span> (242.77 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m62,148\u001b[0m (242.77 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62,148</span> (242.77 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m62,148\u001b[0m (242.77 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#------------------------------------------------------------------------------#\n",
        "# Create model.\n",
        "#------------------------------------------------------------------------------#\n",
        "\n",
        "model = Sequential()\n",
        "model.add(GRU(64, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
        "model.add(GRU(32, activation='relu', return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(future_num))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzsbmrDtj6F4"
      },
      "outputs": [],
      "source": [
        "def create_target_sequences(df, past_num, future_num):\n",
        "  trainYs = []\n",
        "\n",
        "  num_cols = df.shape[1]\n",
        "\n",
        "  for target_col_index in range(num_cols):\n",
        "    trainY = []\n",
        "\n",
        "    for i in range(past_num, len(df) - future_num+1):\n",
        "        target = df[i:i + future_num, target_col_index]\n",
        "        trainY.append(target)\n",
        "    trainYs.append(trainY)\n",
        "\n",
        "  trainYs = np.array(trainYs)\n",
        "\n",
        "  return trainYs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKD1kBg4kDXW",
        "outputId": "eac73408-f411-4912-e824-51350eeba235"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 154ms/step - loss: 0.5144 - val_loss: 3.5224\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 151ms/step - loss: 0.0768 - val_loss: 3.5170\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 151ms/step - loss: 0.0529 - val_loss: 2.9044\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 151ms/step - loss: 0.0480 - val_loss: 3.0505\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 151ms/step - loss: 0.0454 - val_loss: 3.2208\n",
            "\n",
            "\n",
            "Training time 0: 248.53663063049316\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.9766 - val_loss: 1.9893\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.6425 - val_loss: 2.1815\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5705 - val_loss: 2.2835\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5240 - val_loss: 2.1762\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4861 - val_loss: 2.2002\n",
            "\n",
            "\n",
            "Training time 1: 240.2391927242279\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.3387 - val_loss: 0.9884\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.0922 - val_loss: 0.9255\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.0775 - val_loss: 1.0269\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.0678 - val_loss: 1.0779\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.0631 - val_loss: 1.0525\n",
            "\n",
            "\n",
            "Training time 2: 239.4498610496521\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 1.0083 - val_loss: 0.9386\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.6751 - val_loss: 0.8874\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5753 - val_loss: 0.9502\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4979 - val_loss: 1.0143\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4489 - val_loss: 0.9966\n",
            "\n",
            "\n",
            "Training time 3: 239.4255142211914\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.3036 - val_loss: 0.3394\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.0424 - val_loss: 0.3085\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.0359 - val_loss: 0.3390\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.0324 - val_loss: 0.3448\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.0297 - val_loss: 0.3122\n",
            "\n",
            "\n",
            "Training time 4: 239.44455361366272\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.9673 - val_loss: 0.9262\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.6640 - val_loss: 0.9786\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5680 - val_loss: 1.0300\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4854 - val_loss: 1.0367\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4344 - val_loss: 1.0292\n",
            "\n",
            "\n",
            "Training time 5: 239.46029210090637\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.8337 - val_loss: 1.7037\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5378 - val_loss: 1.7456\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4619 - val_loss: 1.7480\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4296 - val_loss: 1.7614\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4044 - val_loss: 1.8259\n",
            "\n",
            "\n",
            "Training time 6: 239.4454596042633\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.9911 - val_loss: 0.7083\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.6172 - val_loss: 0.7013\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5245 - val_loss: 0.7176\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4730 - val_loss: 0.7455\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4500 - val_loss: 0.7542\n",
            "\n",
            "\n",
            "Training time 7: 239.34780716896057\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.8517 - val_loss: 0.9240\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5167 - val_loss: 0.9305\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4511 - val_loss: 0.9471\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4161 - val_loss: 0.8956\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.3893 - val_loss: 0.8779\n",
            "\n",
            "\n",
            "Training time 8: 239.46170330047607\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.7239 - val_loss: 1.4659\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5522 - val_loss: 1.4791\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5039 - val_loss: 1.4707\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4611 - val_loss: 1.4662\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4485 - val_loss: 1.4701\n",
            "\n",
            "\n",
            "Training time 9: 239.53920555114746\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.8408 - val_loss: 1.3114\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4894 - val_loss: 1.3213\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4284 - val_loss: 1.3191\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4047 - val_loss: 1.3380\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.3895 - val_loss: 1.3645\n",
            "\n",
            "\n",
            "Training time 10: 239.56814050674438\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.9691 - val_loss: 1.3084\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.6626 - val_loss: 1.3890\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5759 - val_loss: 1.4595\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5239 - val_loss: 1.4516\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4813 - val_loss: 1.4594\n",
            "\n",
            "\n",
            "Training time 11: 239.55433130264282\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.9537 - val_loss: 1.7324\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.6601 - val_loss: 1.8101\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5637 - val_loss: 1.8515\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5101 - val_loss: 1.9567\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4785 - val_loss: 1.9379\n",
            "\n",
            "\n",
            "Training time 12: 239.610426902771\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 1.0536 - val_loss: 1.5264\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.7810 - val_loss: 1.5202\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.7143 - val_loss: 1.5286\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.6718 - val_loss: 1.5523\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.6565 - val_loss: 1.5508\n",
            "\n",
            "\n",
            "Training time 13: 239.61059403419495\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5883 - val_loss: 2.4250\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4017 - val_loss: 2.4134\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.3539 - val_loss: 2.4209\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.3297 - val_loss: 2.4298\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.3145 - val_loss: 2.3873\n",
            "\n",
            "\n",
            "Training time 14: 239.51268029212952\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.8300 - val_loss: 0.9518\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5176 - val_loss: 0.9481\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4668 - val_loss: 0.9600\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4433 - val_loss: 0.9954\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4188 - val_loss: 1.0199\n",
            "\n",
            "\n",
            "Training time 15: 239.49024081230164\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.9720 - val_loss: 0.8118\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5791 - val_loss: 0.8938\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4762 - val_loss: 0.9081\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4336 - val_loss: 0.9379\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4089 - val_loss: 0.9887\n",
            "\n",
            "\n",
            "Training time 16: 239.43733382225037\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 1.1136 - val_loss: 1.1272\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.7933 - val_loss: 1.1115\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.6953 - val_loss: 1.1658\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.6462 - val_loss: 1.1556\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5979 - val_loss: 1.2069\n",
            "\n",
            "\n",
            "Training time 17: 239.53024816513062\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.7537 - val_loss: 2.1634\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5290 - val_loss: 2.2052\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4925 - val_loss: 2.3277\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4684 - val_loss: 2.3968\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4477 - val_loss: 2.3461\n",
            "\n",
            "\n",
            "Training time 18: 239.50591850280762\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.8379 - val_loss: 1.4073\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5933 - val_loss: 1.4554\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5346 - val_loss: 1.4181\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4978 - val_loss: 1.3705\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4821 - val_loss: 1.3756\n",
            "\n",
            "\n",
            "Training time 19: 239.43097472190857\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.8728 - val_loss: 1.6796\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5288 - val_loss: 1.6539\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4752 - val_loss: 1.6833\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4546 - val_loss: 1.6756\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4379 - val_loss: 1.6629\n",
            "\n",
            "\n",
            "Training time 20: 239.4771945476532\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.9722 - val_loss: 1.2886\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.7164 - val_loss: 1.3023\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.6622 - val_loss: 1.3257\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.6434 - val_loss: 1.3668\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.6252 - val_loss: 1.3359\n",
            "\n",
            "\n",
            "Training time 21: 239.5453724861145\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.8971 - val_loss: 1.3749\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.6576 - val_loss: 1.2838\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.6241 - val_loss: 1.2690\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5973 - val_loss: 1.2730\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5901 - val_loss: 1.2805\n",
            "\n",
            "\n",
            "Training time 22: 239.5433430671692\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.9455 - val_loss: 1.4079\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.6808 - val_loss: 1.4951\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5961 - val_loss: 1.6262\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5356 - val_loss: 1.6623\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4873 - val_loss: 1.6444\n",
            "\n",
            "\n",
            "Training time 23: 239.5761194229126\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5631 - val_loss: 1.2739\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4872 - val_loss: 1.2731\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4678 - val_loss: 1.2138\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4456 - val_loss: 1.1920\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4319 - val_loss: 1.2481\n",
            "\n",
            "\n",
            "Training time 24: 239.5200035572052\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.7489 - val_loss: 3.4829\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4478 - val_loss: 3.4983\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4072 - val_loss: 3.4266\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.3851 - val_loss: 3.4613\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.3822 - val_loss: 3.4647\n",
            "\n",
            "\n",
            "Training time 25: 239.503981590271\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.8330 - val_loss: 1.6686\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5405 - val_loss: 1.7027\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4688 - val_loss: 1.6792\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4347 - val_loss: 1.6728\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4155 - val_loss: 1.6671\n",
            "\n",
            "\n",
            "Training time 26: 239.65780901908875\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 1.0939 - val_loss: 0.7961\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.7247 - val_loss: 0.8541\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.6217 - val_loss: 0.8868\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5497 - val_loss: 0.9040\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5161 - val_loss: 0.8921\n",
            "\n",
            "\n",
            "Training time 27: 239.95804142951965\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.8994 - val_loss: 1.9308\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5669 - val_loss: 1.9910\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5093 - val_loss: 1.9288\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4892 - val_loss: 1.8737\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4764 - val_loss: 1.8615\n",
            "\n",
            "\n",
            "Training time 28: 239.70863604545593\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.7403 - val_loss: 0.6689\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4624 - val_loss: 0.6985\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4151 - val_loss: 0.7309\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.3941 - val_loss: 0.7607\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.3813 - val_loss: 0.7136\n",
            "\n",
            "\n",
            "Training time 29: 239.67223119735718\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.8107 - val_loss: 1.1986\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5624 - val_loss: 1.2770\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5041 - val_loss: 1.2286\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4573 - val_loss: 1.2569\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4405 - val_loss: 1.2253\n",
            "\n",
            "\n",
            "Training time 30: 239.70892477035522\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5888 - val_loss: 3.2929\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.2712 - val_loss: 3.1734\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.2416 - val_loss: 3.2085\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.2267 - val_loss: 3.2109\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.2169 - val_loss: 3.2135\n",
            "\n",
            "\n",
            "Training time 31: 239.64895057678223\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.8478 - val_loss: 0.8174\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4746 - val_loss: 0.8621\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.4015 - val_loss: 0.9475\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.3708 - val_loss: 0.9716\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.3516 - val_loss: 1.0265\n",
            "\n",
            "\n",
            "Training time 32: 239.72259521484375\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 1.1904 - val_loss: 0.8060\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.7495 - val_loss: 0.8613\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.6200 - val_loss: 0.9396\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5549 - val_loss: 0.9461\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5094 - val_loss: 0.9860\n",
            "\n",
            "\n",
            "Training time 33: 239.63648009300232\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 1.0025 - val_loss: 1.7568\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.6973 - val_loss: 1.8037\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.6088 - val_loss: 1.8399\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5595 - val_loss: 1.8843\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5158 - val_loss: 1.9110\n",
            "\n",
            "\n",
            "Training time 34: 239.67651176452637\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 1.1738 - val_loss: 1.1394\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.8455 - val_loss: 1.2087\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.7098 - val_loss: 1.2574\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.6366 - val_loss: 1.3019\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5890 - val_loss: 1.3274\n",
            "\n",
            "\n",
            "Training time 35: 239.66006302833557\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 1.0574 - val_loss: 0.8954\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.7828 - val_loss: 0.9089\n",
            "Epoch 3/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.6883 - val_loss: 0.9185\n",
            "Epoch 4/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.6355 - val_loss: 0.9227\n",
            "Epoch 5/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.5921 - val_loss: 0.9495\n",
            "\n",
            "\n",
            "Training time 36: 239.66235780715942\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 1.1668 - val_loss: 0.6170\n",
            "Epoch 2/5\n",
            "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 150ms/step - loss: 0.8030 - val_loss: 0.6881\n",
            "Epoch 3/5\n",
            "\u001b[1m154/315\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 146ms/step - loss: 0.6869"
          ]
        }
      ],
      "source": [
        "#------------------------------------------------------------------------------#\n",
        "# Generate predictions.\n",
        "#------------------------------------------------------------------------------#\n",
        "\n",
        "# Create target sequences for each column.\n",
        "trainYs = create_target_sequences(scaled_training_df, past_num, future_num)\n",
        "\n",
        "import time\n",
        "\n",
        "predictions = []\n",
        "input_sequence = np.expand_dims(trainX[-1], axis=0)\n",
        "\n",
        "for target_col_index in range(trainYs.shape[0]):  # Iterate over target columns\n",
        "    column_name = columns[target_col_index]\n",
        "    trainY = trainYs[target_col_index].reshape(-1, future_num)\n",
        "    start_time = time.time()\n",
        "    history = model.fit(trainX,\n",
        "                        trainY,\n",
        "                        epochs=5,\n",
        "                        batch_size=32,\n",
        "                        validation_split=0.1,\n",
        "                        verbose=1)\n",
        "    end_time = time.time()\n",
        "    print(f'\\n\\nTraining time {target_col_index}:', end_time - start_time)\n",
        "\n",
        "    plt.figure(figsize=(4,1.5))\n",
        "    plt.plot(history.history['loss'], label='Training loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Predict values for the last window.\n",
        "    predicted_values = model.predict(input_sequence)\n",
        "\n",
        "    predicted_sequence = trainX[-1]\n",
        "\n",
        "    # Replace target column in the predicted_sequence with the predicted_values across all rows.\n",
        "    for i in range(len(predicted_values[0])):\n",
        "        predicted_sequence[i][target_col_index] = predicted_values[0][i]\n",
        "\n",
        "new_df = pd.DataFrame(predicted_sequence, columns=df_train.columns)\n",
        "prediction_rescaled = scalar.inverse_transform(new_df)\n",
        "\n",
        "df_forecast = pd.DataFrame(prediction_rescaled, columns=columns)\n",
        "df_forecast['time'] = df['time'].iloc[-future_num:].values\n",
        "df_forecast['time']=pd.to_datetime(df_forecast['time'])\n",
        "\n",
        "original = df\n",
        "original['time']=pd.to_datetime(original['time'])\n",
        "\n",
        "for target_col_index in range(trainYs.shape[0]):\n",
        "\n",
        "    column_name = columns[target_col_index]\n",
        "\n",
        "    plt.figure(figsize=(16,6))\n",
        "    sns.lineplot(data=original, x='time', y=column_name, label='Original', color='blue')\n",
        "    sns.lineplot(data=df_forecast, x='time', y=column_name, label='Forecast', color='orange')\n",
        "    plt.legend()\n",
        "    plt.title(f'{column_name} Forecast')\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOEPdU5-fY-2"
      },
      "outputs": [],
      "source": [
        "# Write predictions to a csv file.\n",
        "df_predictions = pd.DataFrame(prediction_rescaled, columns=columns)\n",
        "df_predictions.to_csv('./predictions.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}